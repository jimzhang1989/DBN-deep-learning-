name: "hcp_rbm_layer3"
model_type: DBN
layer {
  name: "input_layer"
  dimensions: 316
  param {
    name: "bias"
    initialization: CONSTANT
  }
  param {
    name: "bias_generative"
    initialization: PRETRAINED
    pretrained_model: "/home/wei/Language/Results_2/hcp_rbm_layer1_LAST"
    pretrained_model_param_name: "bias"
  }

  is_input: true
  data_field {
    train: "hcpData"
  }
}
layer {
  name: "hidden1"
  dimensions: 100
  param {
    name: "bias_generative"
    initialization: PRETRAINED
    pretrained_model: "/home/wei/Language/Results_2/hcp_rbm_layer2_rbm_LAST"
  }
  param {
    name: "bias"
    initialization: PRETRAINED
    pretrained_model: "/home/wei/Language/Results_2/hcp_rbm_layer1_LAST"
  }
}
layer {
  name: "hidden2"
  dimensions: 50
  param {
    name: "bias_generative"
    initialization: CONSTANT
  }
  param {
    name: "bias"
    initialization: PRETRAINED
    pretrained_model: "/home/wei/Language/Results_2/hcp_rbm_layer2_rbm_LAST"
  }
  loss_function: SQUARED_LOSS
  performance_stats {
    compute_error: true
  }

}
layer {
  name: "hidden3"
  dimensions: 50
  param {
    name: "bias"
    initialization: CONSTANT
  }
  performance_stats {
    compute_sparsity: true
  }
}
edge {
  node1: "hidden1"
  node2: "input_layer"
  param {
    name: "weight"
    initialization: PRETRAINED
    pretrained_model: "/home/wei/Language/Results_2/hcp_rbm_layer1_LAST"
    transpose_pretrained: true
  }
}
edge {
  node1: "hidden2"
  node2: "hidden1"
  param {
    name: "weight"
    initialization: PRETRAINED
    pretrained_model: "/home/wei/Language/Results_2/hcp_rbm_layer2_rbm_LAST"
    transpose_pretrained: true
  }
}
edge {
  node1: "hidden2"
  node2: "hidden3"
  directed: false
  param {
    name: "weight"
    initialization: DENSE_GAUSSIAN_SQRT_FAN_IN
    sigma: 1.0
  }
}
hyperparams {
  base_epsilon: 0.01
  epsilon_decay: INVERSE_T
  epsilon_decay_half_life: 1000
  initial_momentum: 0.5
  final_momentum: 0.9
  momentum_change_steps: 3000
  sparsity: true
  sparsity_target: 0.1
  sparsity_cost: 0.1
  sparsity_damping: 0.9
  dropout: false
  dropout_prob: 0.5
  apply_weight_norm: false
  weight_norm: 3.0
  apply_l2_decay: false
  l2_decay: 0.001
  apply_l1_decay: false
  l1_decay: 0.1
  activation: LOGISTIC
  mf_steps: 1
  gibbs_steps: 1
}
